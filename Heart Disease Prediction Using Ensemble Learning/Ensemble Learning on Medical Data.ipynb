{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b05348ee-6f0d-4871-b4ca-1edc5f984304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e71806f-0b92-45fd-9604-1887cdae156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELMClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hidden_neurons=100):\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        input_size = X.shape[1]\n",
    "        self.input_weights = np.random.normal(size=[input_size, self.hidden_neurons])\n",
    "        self.biases = np.random.normal(size=[self.hidden_neurons])\n",
    "        H = np.tanh(np.dot(X, self.input_weights) + self.biases)\n",
    "        self.output_weights = np.dot(np.linalg.pinv(H), y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        H = np.tanh(np.dot(X, self.input_weights) + self.biases)\n",
    "        predictions = np.dot(H, self.output_weights)\n",
    "        return (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0493b2b-79ae-4b8a-914d-178f9a8f4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_info = {\n",
    "    'heart_failure_clinical_records_dataset': {\n",
    "        'filename': 'heart_failure_clinical_records_dataset.csv',\n",
    "        'features': ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
    "                     'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
    "                     'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time'],\n",
    "        'target': 'DEATH_EVENT'\n",
    "    },\n",
    "    'statlog': {\n",
    "        'filename': 'statlog.csv',\n",
    "        'features': ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
    "        'target': 'presence',\n",
    "        'adjust_target': True  # Specific to statlog dataset\n",
    "    },\n",
    "    'heart': {\n",
    "        'filename': 'heart.csv',\n",
    "        'features': ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
    "        'target': 'target'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d07d64-6211-4428-914b-5e03570498e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'ELM': ELMClassifier(hidden_neurons=100),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
    "    'Bagging': BaggingClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b619ab-c714-4232-8450-5b528d905b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'RandomForest': {'n_estimators': [10, 50, 100, 200, 500]},\n",
    "    'AdaBoost': {'n_estimators': [50, 100, 200, 500]},\n",
    "    'XGBoost': {'n_estimators': [50, 100, 200, 500]},\n",
    "    'Bagging': {'n_estimators': [10, 50, 100, 200, 500]}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de050e9-ac25-430b-8914-8d28e917e595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: heart_failure_clinical_records_dataset\n",
      "Cross-validation results:\n",
      "              Accuracy\n",
      "ELM           0.740761\n",
      "RandomForest  0.874638\n",
      "AdaBoost      0.841123\n",
      "XGBoost       0.857971\n",
      "Bagging       0.816304\n",
      "\n",
      "Best parameters found:\n",
      "              RandomForest  AdaBoost  XGBoost  Bagging\n",
      "n_estimators            10        50      500       50\n",
      "\n",
      "Accuracy of ELM: 68.33%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75        35\n",
      "           1       0.67      0.48      0.56        25\n",
      "\n",
      "    accuracy                           0.68        60\n",
      "   macro avg       0.68      0.65      0.66        60\n",
      "weighted avg       0.68      0.68      0.67        60\n",
      "\n",
      "\n",
      "Accuracy of RandomForest: 68.33%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.77        35\n",
      "           1       0.71      0.40      0.51        25\n",
      "\n",
      "    accuracy                           0.68        60\n",
      "   macro avg       0.69      0.64      0.64        60\n",
      "weighted avg       0.69      0.68      0.66        60\n",
      "\n",
      "\n",
      "Accuracy of AdaBoost: 75.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        35\n",
      "           1       0.75      0.60      0.67        25\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.75      0.73      0.73        60\n",
      "weighted avg       0.75      0.75      0.74        60\n",
      "\n",
      "\n",
      "Accuracy of XGBoost: 76.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82        35\n",
      "           1       0.79      0.60      0.68        25\n",
      "\n",
      "    accuracy                           0.77        60\n",
      "   macro avg       0.77      0.74      0.75        60\n",
      "weighted avg       0.77      0.77      0.76        60\n",
      "\n",
      "\n",
      "Accuracy of Bagging: 68.33%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75        35\n",
      "           1       0.65      0.52      0.58        25\n",
      "\n",
      "    accuracy                           0.68        60\n",
      "   macro avg       0.68      0.66      0.66        60\n",
      "weighted avg       0.68      0.68      0.68        60\n",
      "\n",
      "\n",
      "Processing dataset: statlog\n",
      "Cross-validation results:\n",
      "              Accuracy\n",
      "ELM           0.735714\n",
      "RandomForest  0.782251\n",
      "AdaBoost      0.759524\n",
      "XGBoost       0.777706\n",
      "Bagging       0.791342\n",
      "\n",
      "Best parameters found:\n",
      "              RandomForest  AdaBoost  XGBoost  Bagging\n",
      "n_estimators            50       100       50      200\n",
      "\n",
      "Accuracy of ELM: 68.52%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74        33\n",
      "           1       0.59      0.62      0.60        21\n",
      "\n",
      "    accuracy                           0.69        54\n",
      "   macro avg       0.67      0.67      0.67        54\n",
      "weighted avg       0.69      0.69      0.69        54\n",
      "\n",
      "\n",
      "Accuracy of RandomForest: 77.78%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        33\n",
      "           1       0.76      0.62      0.68        21\n",
      "\n",
      "    accuracy                           0.78        54\n",
      "   macro avg       0.77      0.75      0.76        54\n",
      "weighted avg       0.78      0.78      0.77        54\n",
      "\n",
      "\n",
      "Accuracy of AdaBoost: 79.63%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84        33\n",
      "           1       0.75      0.71      0.73        21\n",
      "\n",
      "    accuracy                           0.80        54\n",
      "   macro avg       0.79      0.78      0.78        54\n",
      "weighted avg       0.79      0.80      0.80        54\n",
      "\n",
      "\n",
      "Accuracy of XGBoost: 85.19%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        33\n",
      "           1       0.88      0.71      0.79        21\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.86      0.83      0.84        54\n",
      "weighted avg       0.86      0.85      0.85        54\n",
      "\n",
      "\n",
      "Accuracy of Bagging: 81.48%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85        33\n",
      "           1       0.79      0.71      0.75        21\n",
      "\n",
      "    accuracy                           0.81        54\n",
      "   macro avg       0.81      0.80      0.80        54\n",
      "weighted avg       0.81      0.81      0.81        54\n",
      "\n",
      "\n",
      "Processing dataset: heart\n",
      "Cross-validation results:\n",
      "              Accuracy\n",
      "ELM           0.874390\n",
      "RandomForest  0.992683\n",
      "AdaBoost      0.936585\n",
      "XGBoost       0.991463\n",
      "Bagging       0.992683\n",
      "\n",
      "Best parameters found:\n",
      "              RandomForest  AdaBoost  XGBoost  Bagging\n",
      "n_estimators           100       500       50       50\n",
      "\n",
      "Accuracy of ELM: 82.44%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82       102\n",
      "           1       0.81      0.84      0.83       103\n",
      "\n",
      "    accuracy                           0.82       205\n",
      "   macro avg       0.82      0.82      0.82       205\n",
      "weighted avg       0.82      0.82      0.82       205\n",
      "\n",
      "\n",
      "Accuracy of RandomForest: 98.54%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      "Accuracy of AdaBoost: 94.63%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       102\n",
      "           1       0.97      0.92      0.95       103\n",
      "\n",
      "    accuracy                           0.95       205\n",
      "   macro avg       0.95      0.95      0.95       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      "\n",
      "\n",
      "Accuracy of XGBoost: 98.54%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      "Accuracy of Bagging: 98.54%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_info in datasets_info.items():\n",
    "    print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(dataset_info['filename'])\n",
    "    features = dataset_info['features']\n",
    "    target = dataset_info['target']\n",
    "\n",
    "    X = df[features].values\n",
    "    y = df[target].values\n",
    "\n",
    "    # Adjust target values for statlog dataset\n",
    "    if 'adjust_target' in dataset_info and dataset_info['adjust_target']:\n",
    "        y = y - 1\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Perform cross-validation for accuracy\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        results[model_name] = scores.mean()\n",
    "\n",
    "    print(\"Cross-validation results:\")\n",
    "    print(pd.DataFrame(results, index=[\"Accuracy\"]).T)\n",
    "\n",
    "    # Perform GridSearchCV for hyperparameter tuning\n",
    "    best_params = {}\n",
    "    for model_name, param_grid in param_grids.items():\n",
    "        if model_name != 'ELM':  # Skip ELM for GridSearchCV as it's custom\n",
    "            grid_search = GridSearchCV(models[model_name], param_grid, cv=10, scoring='accuracy')\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_params[model_name] = grid_search.best_params_\n",
    "\n",
    "    print(\"\\nBest parameters found:\")\n",
    "    print(pd.DataFrame(best_params))\n",
    "    \n",
    "    # Evaluate models with best parameters\n",
    "    final_results = {}\n",
    "    for model_name, model in models.items():\n",
    "        if model_name in best_params:\n",
    "            model.set_params(**best_params[model_name])\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        final_results[model_name] = {\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Classification Report\": report\n",
    "        }\n",
    "\n",
    "    # Print final evaluation results\n",
    "    for model_name, result in final_results.items():\n",
    "        print(f\"\\nAccuracy of {model_name}: {result['Accuracy'] * 100:.2f}%\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(result['Classification Report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878b8bd-a4f8-4d64-8558-fbcb29c6bc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
